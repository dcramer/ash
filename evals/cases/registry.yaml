name: Agent Registry Behavior
description: Tests agent delegation chains and error recovery via the use_agent tool

cases:
  - id: registry_delegation_chain
    description: Delegate to research agent, then use findings to create a plan
    prompt: "Research Python async best practices, then use those findings to create an implementation plan"
    expected_behavior: |
      The assistant should:
      1. Delegate to the research agent to find Python async best practices
      2. Use the research findings as context for a follow-up delegation
         to the plan agent (or create a plan itself)

      This tests multi-agent delegation where one agent's output feeds
      into the next agent's input.
    criteria:
      - Uses use_agent to invoke the research agent
      - Research results contain substantive async best practices
      - Creates or delegates creation of an implementation plan
      - Plan incorporates findings from the research step
    expected_tools:
      - use_agent
    tags:
      - registry
      - delegation
      - multi_agent

  - id: registry_error_recovery
    description: Handle a nonexistent agent gracefully and fall back to an available one
    prompt: "Use the foobar agent to analyze Python async patterns, and if that doesn't work, try the research agent instead"
    expected_behavior: |
      The assistant should:
      1. Attempt to use "foobar" agent (or recognize it doesn't exist)
      2. Recover by falling back to the research agent
      3. Complete the task using the research agent

      This tests error handling in agent delegation â€” the assistant should
      not give up when one agent fails but should try alternatives.
    criteria:
      - Recognizes that foobar agent does not exist or fails
      - Falls back to the research agent
      - Completes the analysis task using an available agent
      - Does not simply refuse or give up
    expected_tools:
      - use_agent
    tags:
      - registry
      - error_handling
      - fallback
