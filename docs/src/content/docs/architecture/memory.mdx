---
title: Memory
description: Storage and semantic search
sidebar:
  order: 6
---

The memory system provides persistent storage and semantic retrieval.

## Components

| Component | Location | Purpose |
|-----------|----------|---------|
| MemoryStore | `memory/store.py` | CRUD operations |
| Embeddings | `memory/embeddings.py` | Vector generation |
| Retrieval | `memory/retrieval.py` | Semantic search |

## Database Schema

### Sessions

Conversations grouped by provider and chat:

```sql
CREATE TABLE sessions (
    id TEXT PRIMARY KEY,
    provider TEXT NOT NULL,
    chat_id TEXT NOT NULL,
    user_id TEXT NOT NULL,
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    metadata JSON
);
```

### Messages

Individual messages within sessions:

```sql
CREATE TABLE messages (
    id TEXT PRIMARY KEY,
    session_id TEXT REFERENCES sessions(id),
    role TEXT NOT NULL,
    content TEXT NOT NULL,
    created_at TIMESTAMP,
    token_count INTEGER,
    metadata JSON
);
```

### Memories

Persistent knowledge entries:

```sql
CREATE TABLE memories (
    id TEXT PRIMARY KEY,
    content TEXT NOT NULL,
    source TEXT,
    created_at TIMESTAMP,
    expires_at TIMESTAMP,
    owner_user_id TEXT,
    metadata JSON
);
```

### Vector Tables

Embeddings stored via sqlite-vec:

```sql
CREATE VIRTUAL TABLE message_embeddings USING vec0(
    message_id TEXT PRIMARY KEY,
    embedding FLOAT[1536]
);

CREATE VIRTUAL TABLE memory_embeddings USING vec0(
    memory_id TEXT PRIMARY KEY,
    embedding FLOAT[1536]
);
```

## Memory Store

Location: `src/ash/memory/store.py`

```python
class MemoryStore:
    async def add_memory(self, content: str, **metadata) -> Memory:
        """Store a new memory."""

    async def get_memory(self, memory_id: str) -> Memory | None:
        """Retrieve a memory by ID."""

    async def search_memories(
        self,
        query: str,
        limit: int = 10,
    ) -> list[Memory]:
        """Semantic search for relevant memories."""

    async def delete_memory(self, memory_id: str) -> bool:
        """Delete a memory."""
```

## Embedding Generation

Location: `src/ash/memory/embeddings.py`

```python
class EmbeddingGenerator:
    async def embed(self, texts: list[str]) -> list[list[float]]:
        """Generate embeddings using configured model."""
```

Uses OpenAI's embedding API via the LLM provider.

## Semantic Search

Location: `src/ash/memory/retrieval.py`

```python
class MemoryRetriever:
    async def retrieve(
        self,
        query: str,
        limit: int = 5,
    ) -> list[Memory]:
        """Find memories similar to query."""
```

Uses sqlite-vec for vector similarity search:

```sql
SELECT m.*, vec_distance_cosine(e.embedding, ?) as distance
FROM memories m
JOIN memory_embeddings e ON m.id = e.memory_id
ORDER BY distance ASC
LIMIT ?
```

## Context Integration

During agent processing:

1. Query embedding is generated
2. Relevant memories are retrieved
3. Memories are injected into system prompt

```python
memories = await retriever.retrieve(user_message, limit=5)
context = format_memories(memories)
system_prompt = f"{base_prompt}\n\nRelevant memories:\n{context}"
```

## Smart Pruning

Messages are pruned to fit token budget:

1. Always keep last N messages (recency window)
2. Prune older messages to fit budget
3. Reserve space for system prompt
