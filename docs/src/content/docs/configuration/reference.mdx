---
title: Configuration Reference
description: Reference for config.toml options
sidebar:
  label: Reference
  order: 2
---

## Globals

```toml
workspace = "~/.ash/workspace"
timezone = "America/Los_Angeles"
```

| Key | Type | Default |
|-----|------|---------|
| `workspace` | path | `~/.ash/workspace` |
| `timezone` | string (IANA TZ) | system timezone |

## Models (`[models.<alias>]`)

```toml
[models.default]
provider = "openai-oauth"
model = "gpt-5.2"
temperature = 0.7
max_tokens = 4096
reasoning = "medium"
```

| Key | Type | Notes |
|-----|------|-------|
| `provider` | `anthropic` \| `openai` \| `openai-oauth` | Required |
| `model` | string | Required |
| `temperature` | float \| null | Optional |
| `max_tokens` | int | Default `4096` |
| `thinking` | `off|minimal|low|medium|high` \| null | Anthropic-specific |
| `reasoning` | `low|medium|high` \| null | OpenAI-specific |

## Provider Keys

```toml
[openai]
api_key = "sk-..."

[anthropic]
api_key = "sk-ant-..."
```

| Section | Key | Env Fallback |
|---------|-----|--------------|
| `[openai]` | `api_key` | `OPENAI_API_KEY` |
| `[anthropic]` | `api_key` | `ANTHROPIC_API_KEY` |

## Sandbox (`[sandbox]`)

```toml
[sandbox]
image = "ash-sandbox:latest"
timeout = 60
memory_limit = "512m"
cpu_limit = 1.0
runtime = "runc"
network_mode = "bridge"
dns_servers = []
http_proxy = ""
workspace_access = "rw"
sessions_access = "ro"
chats_access = "ro"
source_access = "none"
mount_prefix = "/ash"
apt_packages = []
python_packages = []
setup_command = ""
```

| Key | Type | Default |
|-----|------|---------|
| `image` | string | `ash-sandbox:latest` |
| `timeout` | int | `60` |
| `memory_limit` | string | `512m` |
| `cpu_limit` | float | `1.0` |
| `runtime` | `runc` \| `runsc` | `runc` |
| `network_mode` | `none` \| `bridge` | `bridge` |
| `dns_servers` | list[string] | `[]` |
| `http_proxy` | string \| null | `null` |
| `workspace_access` | `none` \| `ro` \| `rw` | `rw` |
| `sessions_access` | `none` \| `ro` | `ro` |
| `chats_access` | `none` \| `ro` | `ro` |
| `source_access` | `none` \| `ro` | `none` |
| `mount_prefix` | string | `/ash` |
| `apt_packages` | list[string] | `[]` |
| `python_packages` | list[string] | `[]` |
| `setup_command` | string \| null | `null` |

## Memory (`[memory]`)

```toml
[memory]
max_context_messages = 20
context_token_budget = 100000
recency_window = 10
system_prompt_buffer = 8000
compaction_enabled = true
auto_gc = true
max_entries = null
extraction_enabled = true
extraction_model = null
extraction_min_message_length = 20
extraction_debounce_seconds = 30
extraction_confidence_threshold = 0.7
extraction_context_messages = 8
extraction_verification_enabled = true
extraction_verification_model = null
```

| Key | Type | Default |
|-----|------|---------|
| `max_context_messages` | int | `20` |
| `context_token_budget` | int | `100000` |
| `recency_window` | int | `10` |
| `system_prompt_buffer` | int | `8000` |
| `compaction_enabled` | bool | `true` |
| `auto_gc` | bool | `true` |
| `max_entries` | int \| null | `null` |
| `extraction_enabled` | bool | `true` |
| `extraction_model` | string \| null | `null` |
| `extraction_min_message_length` | int | `20` |
| `extraction_debounce_seconds` | int | `30` |
| `extraction_confidence_threshold` | float | `0.7` |
| `extraction_context_messages` | int | `8` |
| `extraction_verification_enabled` | bool | `true` |
| `extraction_verification_model` | string \| null | `null` |

## Vision (`[image]`)

```toml
[image]
enabled = true
provider = "openai"
model = null
max_images_per_message = 1
max_image_bytes = 8000000
request_timeout_seconds = 12.0
include_ocr_text = true
inject_position = "prepend"
no_caption_auto_respond = true
```

| Key | Type | Default |
|-----|------|---------|
| `enabled` | bool | `true` |
| `provider` | `openai` | `openai` |
| `model` | string \| null | `null` |
| `max_images_per_message` | int | `1` |
| `max_image_bytes` | int | `8000000` |
| `request_timeout_seconds` | float | `12.0` |
| `include_ocr_text` | bool | `true` |
| `inject_position` | `prepend` \| `append` | `prepend` |
| `no_caption_auto_respond` | bool | `true` |

## Todos (`[todo]`)

```toml
[todo]
enabled = true
```

| Key | Type | Default |
|-----|------|---------|
| `enabled` | bool | `true` |

## Browser (`[browser]`)

```toml
[browser]
enabled = true
provider = "sandbox"
timeout_seconds = 30.0
max_session_minutes = 20
artifacts_retention_days = 7
state_dir = null
default_viewport_width = 1280
default_viewport_height = 720

[browser.sandbox]
headless = true
browser_channel = "chromium"
runtime_required = true

[browser.kernel]
api_key = null
base_url = "https://api.kernel.sh"
project_id = null
```

| Key | Type | Default |
|-----|------|---------|
| `enabled` | bool | `true` |
| `provider` | `sandbox` \| `kernel` | `sandbox` |
| `timeout_seconds` | float | `30.0` |
| `max_session_minutes` | int | `20` |
| `artifacts_retention_days` | int | `7` |
| `state_dir` | path \| null | `null` |
| `default_viewport_width` | int | `1280` |
| `default_viewport_height` | int | `720` |
| `browser.sandbox.headless` | bool | `true` |
| `browser.sandbox.browser_channel` | `chromium` | `chromium` |
| `browser.sandbox.runtime_required` | bool | `true` |
| `browser.kernel.api_key` | secret \| null | `null` |
| `browser.kernel.base_url` | string | `https://api.kernel.sh` |
| `browser.kernel.project_id` | string \| null | `null` |

For `provider = "sandbox"`, browser execution is expected in sandbox/container runtime.
Set `browser.sandbox.runtime_required = false` only for local development/testing.

Install Playwright Chromium:

```bash
uv run playwright install chromium
```

## Conversation (`[conversation]`)

```toml
[conversation]
recency_window = 10
gap_threshold_minutes = 15
reply_context_window = 3
chat_history_limit = 5
```

## Sessions (`[sessions]`)

```toml
[sessions]
mode = "persistent"
max_concurrent = 2
```

## Embeddings (`[embeddings]`)

```toml
[embeddings]
provider = "openai"
model = "text-embedding-3-small"
```

## Skills

```toml
[skills]
auto_sync = false
update_interval_minutes = 5

[skills.defaults]
allow_chat_ids = ["12345"]  # Optional default chat allowlist for all skills

[[skills.sources]]
repo = "owner/repo"

[skills.research]
enabled = true
model = "mini"
allow_chat_ids = ["12345"]  # Optional per-skill override
PERPLEXITY_API_KEY = "..."
```

## Capabilities (`[capabilities.providers.<name>]`)

```toml
[capabilities.providers.gog]
enabled = true
namespace = "gog"
command = ["gogcli", "bridge"]
timeout_seconds = 30
```

| Key | Type | Default | Notes |
|-----|------|---------|-------|
| `enabled` | bool | `true` | Disable provider without removing config |
| `namespace` | string \| null | `null` | Optional explicit namespace override |
| `command` | list[string] \| string | required | Bridge command launched by host |
| `timeout_seconds` | float | `30.0` | Provider call timeout (1-300) |

Skill metadata should declare required capability IDs only. Bridge command/container wiring lives in host config.

## Agents (`[agents.<name>]`)

```toml
[agents.research]
model = "codex"
max_iterations = 50
```

## Other Optional Sections

```toml
[env]
FOO = "bar"
HOME_DIR = "$HOME"

[telegram]
bot_token = "123:abc"
allowed_users = ["@me"]
allowed_groups = []
group_mode = "mention"

[telegram.passive]
enabled = false

[brave_search]
api_key = "..."

[sentry]
dsn = "https://..."

[server]
host = "127.0.0.1"
port = 8080
webhook_path = "/webhook"
```
